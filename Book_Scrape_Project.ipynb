{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52069286-13fe-4542-ab00-e0d7bb8a7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# Import the requests package\n",
    "import requests\n",
    "\n",
    "# Import the beautifulsoup package\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Import time to do some time tracking of the processing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8de70d2-0f1b-4f8c-aacb-7d97846a8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function that creates a list of book categories by passing the url and returning a list of categories\n",
    "def get_book_categories(site_url):\n",
    "    page = requests.get(site_url)\n",
    "\n",
    "    # create soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    #look for the side_categories container\n",
    "    category_container = soup.find(\"div\", class_=\"side_categories\")\n",
    "\n",
    "    #create a list to store all the extracted categories\n",
    "    category_list = {}\n",
    "    for category in category_container.find_all(\"a\", href=True):\n",
    "        key = category.text.strip()\n",
    "        value = \"https://books.toscrape.com/\"+category[\"href\"]\n",
    "        category_list[key] = value\n",
    "\n",
    "    #remove first item in the list since it is a header\n",
    "    category_list.pop(list(category_list.keys())[0])\n",
    "    \n",
    "    return category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e948654-ffb0-4542-ab3c-321ce7dae628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the books on a page\n",
    "def get_books_in_category(category_url):\n",
    "    books_in_category_url = []\n",
    "    books_in_category_url.clear()\n",
    "\n",
    "    base_url = category_url.split(\"index.html\")[0]\n",
    "    current_page_index = \"index.html\"\n",
    "\n",
    "    #check to see if the page has pagination, if it does will loop the pages\n",
    "    while True:\n",
    "        current_page_url = base_url+current_page_index\n",
    "        page = requests.get(current_page_url)\n",
    "\n",
    "        # create soup object\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        #look for books in the table on the page\n",
    "        books_container = soup.find_all(\"h3\")\n",
    "\n",
    "        #get the URL of the books on the current page\n",
    "        for image_container in books_container:\n",
    "            book_href = image_container.find(\"a\", href=True)\n",
    "            books_in_category_url.append(\"https://books.toscrape.com/catalogue/\"+book_href[\"href\"].replace(\"../../../\",\"\"))    \n",
    "\n",
    "        #check to see if there is another page\n",
    "        next_page = (soup.find(\"li\", class_=\"next\"))\n",
    "\n",
    "        #if there is a next page, get the url of the page\n",
    "        if next_page:\n",
    "            current_page_index = next_page.find(\"a\")[\"href\"]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    #print(books_in_category_url)\n",
    "\n",
    "    return books_in_category_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2acfc08-320d-4f83-9d82-b1ad0101dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function which scrapes data for a single book, pass URL return elements\n",
    "def scrape_book_data(book_page_url):\n",
    "    print(book_page_url)\n",
    "    # set the page variable to the extract of the url's HTML\n",
    "    page = requests.get(book_page_url)\n",
    "    \n",
    "    # create soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Get the Product Description\n",
    "    #find the description container by ID\n",
    "    description_container = soup.find(\"div\", id=\"product_description\")\n",
    "    #find the next P tag after the descrption container\n",
    "    product_description =  description_container.find_next(\"p\").text.strip()\n",
    "    #print(product_description)\n",
    "\n",
    "    # Get book category\n",
    "    breadcrumb_container = soup.find(\"ul\", class_=\"breadcrumb\")\n",
    "    #print(breadcrumb_container)\n",
    "\n",
    "    #extract all the A from the container\n",
    "    list_item = breadcrumb_container.find_all(\"a\")\n",
    "    #print(list_item)\n",
    "\n",
    "    #get the category as the 3rd entry in the list\n",
    "    category = list_item[2].text.strip()\n",
    "    #print(category)\n",
    "\n",
    "    # Get the book Title as the 4th entry in the list\n",
    "    book_title = breadcrumb_container.find(\"li\",class_=\"active\").text\n",
    "    #print(book_title)\n",
    "\n",
    "    # Get the rating from the product_main div by extracting the class for star-rating\n",
    "    rating_container = soup.find(\"div\",class_=\"col-sm-6 product_main\")\n",
    "    review_rating = rating_container.find(\"p\", class_=\"star-rating\").get(\"class\")[1]\n",
    "    #print(review_rating)\n",
    "\n",
    "    # Get the Product Information table data\n",
    "    product_information_container = soup.find(\"table\", class_=\"table table-striped\")\n",
    "\n",
    "    # since we need to extract multiple data points from the table, create a dictionary to store all the data points in the product information table\n",
    "    product_information = {}\n",
    "\n",
    "    # loop the rows in the container looking for the table row (TR) tag\n",
    "    for table_row in product_information_container.find_all(\"tr\"):\n",
    "        # define the key as the extracted table header (TH)\n",
    "        key = table_row.find(\"th\").text.strip()\n",
    "        # define the value as the extracted table description (TD)\n",
    "        value = table_row.find(\"td\").text.strip()\n",
    "\n",
    "        #write the key:value pair to the dictionary\n",
    "        product_information[key] = value\n",
    "\n",
    "    #print(product_information)\n",
    "\n",
    "    #define the variables of the required information\n",
    "    universal_product_code = product_information[\"UPC\"]\n",
    "    price_including_tax = product_information[\"Price (incl. tax)\"]\n",
    "    price_excluding_tax = product_information[\"Price (excl. tax)\"]\n",
    "    quantity_available = product_information[\"Availability\"]   #NEED TO EXTRACT JUST THE NUMBER ONLY this should be fine as is without extracting extra number. if extract number , do regex\n",
    "    #print(quantity_available)\n",
    "\n",
    "    # Get the Image URL\n",
    "    thumbnail_container = soup.find(\"div\",class_=\"thumbnail\")\n",
    "    #print(thumbnail_container)\n",
    "\n",
    "    image_url = \"https://books.toscrape.com\"+thumbnail_container.find(\"img\")[\"src\"].replace(\"../..\",\"\")\n",
    "    #print(image_url)\n",
    "\n",
    "    book_extracted_information = [book_page_url,universal_product_code,book_title,price_including_tax,price_excluding_tax,quantity_available,product_description,category,review_rating,image_url]\n",
    "\n",
    "    return book_extracted_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26a8cb90-a033-44c4-b537-149dc8ea95cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting category: Travel     URL: https://books.toscrape.com/catalogue/category/books/travel_2/index.html     Start Time: 8982.9822386\n",
      "Gathered book list in Travel category: 11 books identified\n",
      "https://books.toscrape.com/catalogue/its-only-the-himalayas_981/index.html\n",
      "https://books.toscrape.com/catalogue/full-moon-over-noahs-ark-an-odyssey-to-mount-ararat-and-beyond_811/index.html\n",
      "https://books.toscrape.com/catalogue/see-america-a-celebration-of-our-national-parks-treasured-sites_732/index.html\n",
      "https://books.toscrape.com/catalogue/vagabonding-an-uncommon-guide-to-the-art-of-long-term-world-travel_552/index.html\n",
      "https://books.toscrape.com/catalogue/under-the-tuscan-sun_504/index.html\n",
      "https://books.toscrape.com/catalogue/a-summer-in-europe_458/index.html\n",
      "https://books.toscrape.com/catalogue/the-great-railway-bazaar_446/index.html\n",
      "https://books.toscrape.com/catalogue/a-year-in-provence-provence-1_421/index.html\n",
      "https://books.toscrape.com/catalogue/the-road-to-little-dribbling-adventures-of-an-american-in-britain-notes-from-a-small-island-2_277/index.html\n",
      "https://books.toscrape.com/catalogue/neither-here-nor-there-travels-in-europe_198/index.html\n",
      "https://books.toscrape.com/catalogue/1000-places-to-see-before-you-die_1/index.html\n",
      "Finished gathering book details for :Travel     End Time: 8987.2463563     Total time: 4.264117700000497\n",
      "Starting category: Mystery     URL: https://books.toscrape.com/catalogue/category/books/mystery_3/index.html     Start Time: 8987.2464168\n",
      "Gathered book list in Mystery category: 32 books identified\n",
      "https://books.toscrape.com/catalogue/sharp-objects_997/index.html\n",
      "https://books.toscrape.com/catalogue/in-a-dark-dark-wood_963/index.html\n",
      "https://books.toscrape.com/catalogue/the-past-never-ends_942/index.html\n",
      "https://books.toscrape.com/catalogue/a-murder-in-time_877/index.html\n",
      "https://books.toscrape.com/catalogue/the-murder-of-roger-ackroyd-hercule-poirot-4_852/index.html\n",
      "https://books.toscrape.com/catalogue/the-last-mile-amos-decker-2_754/index.html\n",
      "https://books.toscrape.com/catalogue/that-darkness-gardiner-and-renner-1_743/index.html\n",
      "https://books.toscrape.com/catalogue/tastes-like-fear-di-marnie-rome-3_742/index.html\n",
      "https://books.toscrape.com/catalogue/a-time-of-torment-charlie-parker-14_657/index.html\n",
      "https://books.toscrape.com/catalogue/a-study-in-scarlet-sherlock-holmes-1_656/index.html\n",
      "https://books.toscrape.com/catalogue/poisonous-max-revere-novels-3_627/index.html\n",
      "https://books.toscrape.com/catalogue/murder-at-the-42nd-street-library-raymond-ambler-1_624/index.html\n",
      "https://books.toscrape.com/catalogue/most-wanted_623/index.html\n",
      "https://books.toscrape.com/catalogue/hide-away-eve-duncan-20_620/index.html\n",
      "https://books.toscrape.com/catalogue/boar-island-anna-pigeon-19_613/index.html\n",
      "https://books.toscrape.com/catalogue/the-widow_609/index.html\n",
      "https://books.toscrape.com/catalogue/playing-with-fire_602/index.html\n",
      "https://books.toscrape.com/catalogue/what-happened-on-beale-street-secrets-of-the-south-mysteries-2_506/index.html\n",
      "https://books.toscrape.com/catalogue/the-bachelor-girls-guide-to-murder-herringford-and-watts-mysteries-1_491/index.html\n",
      "https://books.toscrape.com/catalogue/delivering-the-truth-quaker-midwife-mystery-1_464/index.html\n",
      "https://books.toscrape.com/catalogue/the-mysterious-affair-at-styles-hercule-poirot-1_452/index.html\n",
      "https://books.toscrape.com/catalogue/in-the-woods-dublin-murder-squad-1_433/index.html\n",
      "https://books.toscrape.com/catalogue/the-silkworm-cormoran-strike-2_280/index.html\n",
      "https://books.toscrape.com/catalogue/the-exiled_247/index.html\n",
      "https://books.toscrape.com/catalogue/the-cuckoos-calling-cormoran-strike-1_239/index.html\n",
      "https://books.toscrape.com/catalogue/extreme-prey-lucas-davenport-26_154/index.html\n",
      "https://books.toscrape.com/catalogue/career-of-evil-cormoran-strike-3_137/index.html\n",
      "https://books.toscrape.com/catalogue/the-no-1-ladies-detective-agency-no-1-ladies-detective-agency-1_76/index.html\n",
      "https://books.toscrape.com/catalogue/the-girl-you-lost_66/index.html\n",
      "https://books.toscrape.com/catalogue/the-girl-in-the-ice-dci-erika-foster-1_65/index.html\n",
      "https://books.toscrape.com/catalogue/blood-defense-samantha-brinkman-1_8/index.html\n",
      "https://books.toscrape.com/catalogue/1st-to-die-womens-murder-club-1_2/index.html\n",
      "Finished gathering book details for :Mystery     End Time: 8999.7244399     Total time: 12.478023099998609\n",
      "Starting category: Historical Fiction     URL: https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html     Start Time: 8999.7244988\n",
      "Gathered book list in Historical Fiction category: 26 books identified\n",
      "https://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html\n",
      "https://books.toscrape.com/catalogue/forever-and-forever-the-courtship-of-henry-longfellow-and-fanny-appleton_894/index.html\n",
      "https://books.toscrape.com/catalogue/a-flight-of-arrows-the-pathfinders-2_876/index.html\n",
      "https://books.toscrape.com/catalogue/the-house-by-the-lake_846/index.html\n",
      "https://books.toscrape.com/catalogue/mrs-houdini_821/index.html\n",
      "https://books.toscrape.com/catalogue/the-marriage-of-opposites_759/index.html\n",
      "https://books.toscrape.com/catalogue/glory-over-everything-beyond-the-kitchen-house_696/index.html\n",
      "https://books.toscrape.com/catalogue/love-lies-and-spies_622/index.html\n",
      "https://books.toscrape.com/catalogue/a-paris-apartment_612/index.html\n",
      "https://books.toscrape.com/catalogue/lilac-girls_597/index.html\n",
      "https://books.toscrape.com/catalogue/the-constant-princess-the-tudor-court-1_493/index.html\n",
      "https://books.toscrape.com/catalogue/the-invention-of-wings_448/index.html\n",
      "https://books.toscrape.com/catalogue/world-without-end-the-pillars-of-the-earth-2_420/index.html\n",
      "https://books.toscrape.com/catalogue/the-passion-of-dolssa_351/index.html\n",
      "https://books.toscrape.com/catalogue/girl-with-a-pearl-earring_322/index.html\n",
      "https://books.toscrape.com/catalogue/voyager-outlander-3_299/index.html\n",
      "https://books.toscrape.com/catalogue/the-red-tent_273/index.html\n",
      "https://books.toscrape.com/catalogue/the-last-painting-of-sara-de-vos_259/index.html\n",
      "https://books.toscrape.com/catalogue/the-guernsey-literary-and-potato-peel-pie-society_253/index.html\n",
      "https://books.toscrape.com/catalogue/girl-in-the-blue-coat_160/index.html\n",
      "https://books.toscrape.com/catalogue/between-shades-of-gray_128/index.html\n",
      "https://books.toscrape.com/catalogue/while-you-were-mine_97/index.html\n",
      "https://books.toscrape.com/catalogue/the-secret-healer_80/index.html\n",
      "https://books.toscrape.com/catalogue/starlark_56/index.html\n",
      "https://books.toscrape.com/catalogue/lost-among-the-living_31/index.html\n",
      "https://books.toscrape.com/catalogue/a-spys-devotion-the-regency-spies-of-london-1_3/index.html\n",
      "Finished gathering book details for :Historical Fiction     End Time: 9010.0841717     Total time: 10.359672900000078\n",
      "Starting category: Sequential Art     URL: https://books.toscrape.com/catalogue/category/books/sequential-art_5/index.html     Start Time: 9010.0842344\n",
      "Gathered book list in Sequential Art category: 75 books identified\n",
      "https://books.toscrape.com/catalogue/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\n",
      "https://books.toscrape.com/catalogue/tsubasa-world-chronicle-2-tsubasa-world-chronicle-2_949/index.html\n",
      "https://books.toscrape.com/catalogue/this-one-summer_947/index.html\n",
      "https://books.toscrape.com/catalogue/the-nameless-city-the-nameless-city-1_940/index.html\n",
      "https://books.toscrape.com/catalogue/saga-volume-5-saga-collected-editions-5_923/index.html\n",
      "https://books.toscrape.com/catalogue/rat-queens-vol-3-demons-rat-queens-collected-editions-11-15_921/index.html\n",
      "https://books.toscrape.com/catalogue/princess-jellyfish-2-in-1-omnibus-vol-01-princess-jellyfish-2-in-1-omnibus-1_920/index.html\n",
      "https://books.toscrape.com/catalogue/pop-gun-war-volume-1-gift_918/index.html\n",
      "https://books.toscrape.com/catalogue/patience_916/index.html\n",
      "https://books.toscrape.com/catalogue/outcast-vol-1-a-darkness-surrounds-him-outcast-1_915/index.html\n",
      "https://books.toscrape.com/catalogue/orange-the-complete-collection-1-orange-the-complete-collection-1_914/index.html\n",
      "https://books.toscrape.com/catalogue/lumberjanes-vol-2-friendship-to-the-max-lumberjanes-5-8_907/index.html\n",
      "https://books.toscrape.com/catalogue/lumberjanes-vol-1-beware-the-kitten-holy-lumberjanes-1-4_906/index.html\n",
      "https://books.toscrape.com/catalogue/lumberjanes-vol-3-a-terrible-plan-lumberjanes-9-12_905/index.html\n",
      "https://books.toscrape.com/catalogue/i-hate-fairyland-vol-1-madly-ever-after-i-hate-fairyland-compilations-1-5_899/index.html\n",
      "https://books.toscrape.com/catalogue/i-am-a-hero-omnibus-volume-1_898/index.html\n",
      "https://books.toscrape.com/catalogue/giant-days-vol-2-giant-days-5-8_895/index.html\n",
      "https://books.toscrape.com/catalogue/danganronpa-volume-1_889/index.html\n",
      "https://books.toscrape.com/catalogue/codename-baboushka-volume-1-the-conclave-of-death_887/index.html\n",
      "https://books.toscrape.com/catalogue/camp-midnight_886/index.html\n",
      "https://books.toscrape.com/catalogue/bitch-planet-vol-1-extraordinary-machine-bitch-planet-collected-editions_882/index.html\n",
      "https://books.toscrape.com/catalogue/the-shadow-hero-the-shadow-hero_860/index.html\n",
      "https://books.toscrape.com/catalogue/fables-vol-1-legends-in-exile-fables-1_806/index.html\n",
      "https://books.toscrape.com/catalogue/batman-the-long-halloween-batman_793/index.html\n",
      "https://books.toscrape.com/catalogue/batman-the-dark-knight-returns-batman_792/index.html\n",
      "https://books.toscrape.com/catalogue/wonder-woman-earth-one-volume-one-wonder-woman-earth-one-1_783/index.html\n",
      "https://books.toscrape.com/catalogue/we-are-robin-vol-1-the-vigilante-business-we-are-robin-1_778/index.html\n",
      "https://books.toscrape.com/catalogue/through-the-woods_772/index.html\n",
      "https://books.toscrape.com/catalogue/superman-vol-1-before-truth-superman-by-gene-luen-yang-1_739/index.html\n",
      "https://books.toscrape.com/catalogue/so-cute-it-hurts-vol-6-so-cute-it-hurts-6_734/index.html\n",
      "https://books.toscrape.com/catalogue/robin-war_730/index.html\n",
      "https://books.toscrape.com/catalogue/red-hoodarsenal-vol-1-open-for-business-red-hoodarsenal-1_729/index.html\n",
      "https://books.toscrape.com/catalogue/naruto-3-in-1-edition-vol-14-includes-vols-40-41-42-naruto-omnibus-14_721/index.html\n",
      "https://books.toscrape.com/catalogue/lowriders-to-the-center-of-the-earth-lowriders-in-space-2_712/index.html\n",
      "https://books.toscrape.com/catalogue/el-deafo_691/index.html\n",
      "https://books.toscrape.com/catalogue/batman-europa_668/index.html\n",
      "https://books.toscrape.com/catalogue/art-ops-vol-1_664/index.html\n",
      "https://books.toscrape.com/catalogue/adulthood-is-a-myth-a-sarahs-scribbles-collection_659/index.html\n",
      "https://books.toscrape.com/catalogue/fruits-basket-vol-9-fruits-basket-9_563/index.html\n",
      "https://books.toscrape.com/catalogue/roller-girl_540/index.html\n",
      "https://books.toscrape.com/catalogue/fruits-basket-vol-7-fruits-basket-7_468/index.html\n",
      "https://books.toscrape.com/catalogue/fruits-basket-vol-6-fruits-basket-6_427/index.html\n",
      "https://books.toscrape.com/catalogue/death-note-vol-6-give-and-take-death-note-6_425/index.html\n",
      "https://books.toscrape.com/catalogue/fruits-basket-vol-5-fruits-basket-5_376/index.html\n",
      "https://books.toscrape.com/catalogue/death-note-vol-5-whiteout-death-note-5_368/index.html\n",
      "https://books.toscrape.com/catalogue/the-demon-prince-of-momochi-house-vol-4-the-demon-prince-of-momochi-house-4_344/index.html\n",
      "https://books.toscrape.com/catalogue/fruits-basket-vol-4-fruits-basket-4_321/index.html\n",
      "https://books.toscrape.com/catalogue/the-wicked-the-divine-vol-3-commercial-suicide-the-wicked-the-divine_287/index.html\n",
      "https://books.toscrape.com/catalogue/the-sandman-vol-3-dream-country-the-sandman-volumes-3_279/index.html\n",
      "https://books.toscrape.com/catalogue/saga-volume-3-saga-collected-editions-3_216/index.html\n",
      "https://books.toscrape.com/catalogue/prodigy-the-graphic-novel-legend-the-graphic-novel-2_207/index.html\n",
      "https://books.toscrape.com/catalogue/persepolis-the-story-of-a-childhood-persepolis-1-2_206/index.html\n",
      "https://books.toscrape.com/catalogue/original-fake_203/index.html\n",
      "https://books.toscrape.com/catalogue/grayson-vol-3-nemesis-grayson-3_164/index.html\n",
      "https://books.toscrape.com/catalogue/fruits-basket-vol-3-fruits-basket-3_159/index.html\n",
      "https://books.toscrape.com/catalogue/black-butler-vol-1-black-butler-1_130/index.html\n",
      "https://books.toscrape.com/catalogue/awkward_124/index.html\n",
      "https://books.toscrape.com/catalogue/the-sandman-vol-2-the-dolls-house-the-sandman-volumes-2_110/index.html\n",
      "https://books.toscrape.com/catalogue/saga-volume-2-saga-collected-editions-2_107/index.html\n",
      "https://books.toscrape.com/catalogue/fruits-basket-vol-2-fruits-basket-2_100/index.html\n",
      "https://books.toscrape.com/catalogue/y-the-last-man-vol-1-unmanned-y-the-last-man-1_98/index.html\n",
      "https://books.toscrape.com/catalogue/the-wicked-the-divine-vol-1-the-faust-act-the-wicked-the-divine_86/index.html\n",
      "https://books.toscrape.com/catalogue/the-sandman-vol-1-preludes-and-nocturnes-the-sandman-volumes-1_79/index.html\n",
      "https://books.toscrape.com/catalogue/the-complete-maus-maus-1-2_62/index.html\n",
      "https://books.toscrape.com/catalogue/skip-beat-vol-01-skip-beat-1_55/index.html\n",
      "https://books.toscrape.com/catalogue/saga-volume-1-saga-collected-editions-1_48/index.html\n",
      "https://books.toscrape.com/catalogue/rat-queens-vol-1-sass-sorcery-rat-queens-collected-editions-1-5_46/index.html\n",
      "https://books.toscrape.com/catalogue/paper-girls-vol-1-paper-girls-1-5_44/index.html\n",
      "https://books.toscrape.com/catalogue/ouran-high-school-host-club-vol-1-ouran-high-school-host-club-1_43/index.html\n",
      "https://books.toscrape.com/catalogue/ms-marvel-vol-1-no-normal-ms-marvel-2014-2015-1_34/index.html\n",
      "https://books.toscrape.com/catalogue/hawkeye-vol-1-my-life-as-a-weapon-hawkeye-1_24/index.html\n",
      "https://books.toscrape.com/catalogue/giant-days-vol-1-giant-days-1-4_22/index.html\n",
      "https://books.toscrape.com/catalogue/fruits-basket-vol-1-fruits-basket-1_21/index.html\n",
      "https://books.toscrape.com/catalogue/bleach-vol-1-strawberry-and-the-soul-reapers-bleach-1_7/index.html\n",
      "https://books.toscrape.com/catalogue/ajin-demi-human-volume-1-ajin-demi-human-1_4/index.html\n",
      "Finished gathering book details for :Sequential Art     End Time: 9040.3303493     Total time: 30.246114900000975\n",
      "Starting category: Classics     URL: https://books.toscrape.com/catalogue/category/books/classics_6/index.html     Start Time: 9040.3304124\n",
      "Gathered book list in Classics category: 19 books identified\n",
      "https://books.toscrape.com/catalogue/the-secret-garden_413/index.html\n",
      "https://books.toscrape.com/catalogue/the-metamorphosis_409/index.html\n",
      "https://books.toscrape.com/catalogue/the-pilgrims-progress_353/index.html\n",
      "https://books.toscrape.com/catalogue/the-hound-of-the-baskervilles-sherlock-holmes-5_348/index.html\n",
      "https://books.toscrape.com/catalogue/little-women-little-women-1_331/index.html\n",
      "https://books.toscrape.com/catalogue/gone-with-the-wind_324/index.html\n",
      "https://books.toscrape.com/catalogue/candide_316/index.html\n",
      "https://books.toscrape.com/catalogue/animal-farm_313/index.html\n",
      "https://books.toscrape.com/catalogue/wuthering-heights_307/index.html\n",
      "https://books.toscrape.com/catalogue/the-picture-of-dorian-gray_270/index.html\n",
      "https://books.toscrape.com/catalogue/the-complete-stories-and-poems-the-works-of-edgar-allan-poe-cameo-edition_238/index.html\n",
      "https://books.toscrape.com/catalogue/beowulf_126/index.html\n",
      "https://books.toscrape.com/catalogue/and-then-there-were-none_119/index.html\n",
      "https://books.toscrape.com/catalogue/the-story-of-hong-gildong_84/index.html\n",
      "https://books.toscrape.com/catalogue/the-little-prince_72/index.html\n",
      "https://books.toscrape.com/catalogue/sense-and-sensibility_49/index.html\n",
      "https://books.toscrape.com/catalogue/of-mice-and-men_37/index.html\n",
      "https://books.toscrape.com/catalogue/emma_17/index.html\n",
      "https://books.toscrape.com/catalogue/alice-in-wonderland-alices-adventures-in-wonderland-1_5/index.html\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_next'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#call the scrape_book_data which is a function that gathers all details about a single book\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m book_url \u001b[38;5;129;01min\u001b[39;00m books_in_category_list:\n\u001b[1;32m---> 20\u001b[0m     scraped_book_data \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_book_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbook_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m#check to see if the extracted book is already in the list of scraped book data, if it is not, add it to the list\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m book_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniversal_product_code\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin([scraped_book_data[\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;241m.\u001b[39many():\n",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m, in \u001b[0;36mscrape_book_data\u001b[1;34m(book_page_url)\u001b[0m\n\u001b[0;32m     12\u001b[0m description_container \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct_description\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#find the next P tag after the descrption container\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m product_description \u001b[38;5;241m=\u001b[39m  \u001b[43mdescription_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_next\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#print(product_description)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Get book category\u001b[39;00m\n\u001b[0;32m     18\u001b[0m breadcrumb_container \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mul\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbreadcrumb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_next'"
     ]
    }
   ],
   "source": [
    "# create a list of data elements which will be used as column headers in the final output\n",
    "book_data = pd.DataFrame(columns=[\"product_page_url\",\"universal_product_code\",\"book_title\",\"price_including_tax\",\"price_excluding_tax\",\"quantity_available\",\"product_description\",\"category\",\"review_rating\",\"image_url\"])\n",
    "\n",
    "# define the URL to scrape data off of and define it as the url variable\n",
    "site_page_url = \"https://books.toscrape.com/\"\n",
    "\n",
    "#gather list of categories by calling function\n",
    "scraped_category_list = get_book_categories(site_page_url)\n",
    "\n",
    "#gather list of books in a category by calling function and passing the category url\n",
    "start_time_all = time.perf_counter()\n",
    "for category, category_url in scraped_category_list.items():\n",
    "    start_time = time.perf_counter()\n",
    "    print(\"Starting category: \"+category+\"     URL: \"+category_url+\"     Start Time: \"+str(start_time))\n",
    "    books_in_category_list = get_books_in_category(category_url)\n",
    "    print(\"Gathered book list in \"+category+\" category: \"+str(len(books_in_category_list))+\" books identified\")\n",
    "\n",
    "    #call the scrape_book_data which is a function that gathers all details about a single book\n",
    "    for book_url in books_in_category_list:\n",
    "        scraped_book_data = scrape_book_data(book_url)\n",
    "\n",
    "        #check to see if the extracted book is already in the list of scraped book data, if it is not, add it to the list\n",
    "        if not book_data[\"universal_product_code\"].isin([scraped_book_data[1]]).any():\n",
    "            book_data.loc[len(book_data)] = scraped_book_data\n",
    "    end_time = time.perf_counter()\n",
    "    print(\"Finished gathering book details for :\"+category+\"     End Time: \"+str(end_time)+\"     Total time: \"+str(end_time-start_time))\n",
    "end_time_all = time.perf_counter()\n",
    "print(\"Completed!\"+\" Start Time: \"+str(start_time_all)+\" End Time: \"+str(end_time_all)+\" Total Time: \"+str(end_time_all-start_time_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e23543-46ec-4e4f-9c60-3a598806d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the book_data dataframe to CSV\n",
    "book_data.to_csv(\"Phase_1_Output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14495dd8-b333-4107-a7d6-db8a6d2b2c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
