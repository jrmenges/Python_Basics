{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52069286-13fe-4542-ab00-e0d7bb8a7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# Import the requests package\n",
    "import requests\n",
    "\n",
    "# Import the beautifulsoup package\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8de70d2-0f1b-4f8c-aacb-7d97846a8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function that creates a list of book categories by passing the url and returning a list of categories\n",
    "def get_book_categories(site_url):\n",
    "    page = requests.get(site_url)\n",
    "\n",
    "    # create soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    #look for the side_categories container\n",
    "    category_container = soup.find(\"div\", class_=\"side_categories\")\n",
    "    #print(category_container)\n",
    "\n",
    "    #create a list to store all the extracted categories\n",
    "    category_list = {}\n",
    "    for category in category_container.find_all(\"a\", href=True):\n",
    "        key = category.text.strip()\n",
    "        value = \"https://books.toscrape.com\"+category[\"href\"]\n",
    "        category_list[key] = value\n",
    "\n",
    "    #remove first item in the list since it is a header\n",
    "    category_list.pop(list(category_list.keys())[0])\n",
    "    #print(category_list)\n",
    "    \n",
    "    return category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e948654-ffb0-4542-ab3c-321ce7dae628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the books on a page\n",
    "def get_books_in_category(site_url):\n",
    "    books_in_category_url = []\n",
    "    books_in_category_url.clear()\n",
    "\n",
    "    base_url = \"https://books.toscrape.com/catalogue/category/books/mystery_3/\"\n",
    "    current_page_index = \"index.html\"\n",
    "\n",
    "    #check to see if the page has pagination, if it does will loop the pages\n",
    "    while True:\n",
    "        current_page_url = base_url+current_page_index\n",
    "        page = requests.get(current_page_url) #has pagination\n",
    "        #page = requests.get(\"https://books.toscrape.com/catalogue/category/books/politics_48/index.html\") #does not have pagination\n",
    "\n",
    "        # create soup object\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        #look for books in the table on the page\n",
    "        books_container = soup.find_all(\"h3\")\n",
    "\n",
    "        #get the URL of the books on the current page\n",
    "        for image_container in books_container:\n",
    "            book_href = image_container.find(\"a\", href=True)\n",
    "            books_in_category_url.append(\"https://books.toscrape.com/catalogue/\"+book_href[\"href\"].replace(\"../../../\",\"\"))    \n",
    "\n",
    "        #check to see if there is another page\n",
    "        next_page = (soup.find(\"li\", class_=\"next\"))\n",
    "\n",
    "        #if there is a next page, get the url of the page\n",
    "        if next_page:\n",
    "            current_page_index = next_page.find(\"a\")[\"href\"]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    #print(books_in_category_url)\n",
    "\n",
    "    return books_in_category_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2acfc08-320d-4f83-9d82-b1ad0101dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function which scrapes data for a single book, pass URL return elements\n",
    "def scrape_book_data(book_page_url):\n",
    "    # set the page variable to the extract of the url's HTML\n",
    "    page = requests.get(book_page_url)\n",
    "    \n",
    "    # create soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Get the Product Description\n",
    "    #find the description container by ID\n",
    "    description_container = soup.find(\"div\", id=\"product_description\")\n",
    "    #find the next P tag after the descrption container\n",
    "    product_description =  description_container.find_next(\"p\").text.strip()\n",
    "    #print(product_description)\n",
    "\n",
    "    # Get book category\n",
    "    breadcrumb_container = soup.find(\"ul\", class_=\"breadcrumb\")\n",
    "    #print(breadcrumb_container)\n",
    "\n",
    "    #extract all the A from the container\n",
    "    list_item = breadcrumb_container.find_all(\"a\")\n",
    "    #print(list_item)\n",
    "\n",
    "    #get the category as the 3rd entry in the list\n",
    "    category = list_item[2].text.strip()\n",
    "    #print(category)\n",
    "\n",
    "    # Get the book Title as the 4th entry in the list\n",
    "    book_title = breadcrumb_container.find(\"li\",class_=\"active\").text\n",
    "    #print(book_title)\n",
    "\n",
    "    # Get the rating from the product_main div by extracting the class for star-rating\n",
    "    rating_container = soup.find(\"div\",class_=\"col-sm-6 product_main\")\n",
    "    review_rating = rating_container.find(\"p\", class_=\"star-rating\").get(\"class\")[1]\n",
    "    #print(review_rating)\n",
    "\n",
    "    # Get the Product Information table data\n",
    "    product_information_container = soup.find(\"table\", class_=\"table table-striped\")\n",
    "\n",
    "    # since we need to extract multiple data points from the table, create a dictionary to store all the data points in the product information table\n",
    "    product_information = {}\n",
    "\n",
    "    # loop the rows in the container looking for the table row (TR) tag\n",
    "    for table_row in product_information_container.find_all(\"tr\"):\n",
    "        # define the key as the extracted table header (TH)\n",
    "        key = table_row.find(\"th\").text.strip()\n",
    "        # define the value as the extracted table description (TD)\n",
    "        value = table_row.find(\"td\").text.strip()\n",
    "\n",
    "        #write the key:value pair to the dictionary\n",
    "        product_information[key] = value\n",
    "\n",
    "    #print(product_information)\n",
    "\n",
    "    #define the variables of the required information\n",
    "    universal_product_code = product_information[\"UPC\"]\n",
    "    price_including_tax = product_information[\"Price (incl. tax)\"]\n",
    "    price_excluding_tax = product_information[\"Price (excl. tax)\"]\n",
    "    quantity_available = product_information[\"Availability\"]   #NEED TO EXTRACT JUST THE NUMBER ONLY this should be fine as is without extracting extra number. if extract number , do regex\n",
    "    #print(quantity_available)\n",
    "\n",
    "    # Get the Image URL\n",
    "    thumbnail_container = soup.find(\"div\",class_=\"thumbnail\")\n",
    "    #print(thumbnail_container)\n",
    "\n",
    "    image_url = \"https://books.toscrape.com\"+thumbnail_container.find(\"img\")[\"src\"].replace(\"../..\",\"\")\n",
    "    #print(image_url)\n",
    "\n",
    "    book_extracted_information = [book_page_url,universal_product_code,book_title,price_including_tax,price_excluding_tax,quantity_available,product_description,category,review_rating,image_url]\n",
    "\n",
    "    return book_extracted_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26a8cb90-a033-44c4-b537-149dc8ea95cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting category: Travel\n",
      "Gathered book list in Travel category: 32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m books_in_category_list \u001b[38;5;241m=\u001b[39m get_books_in_category(category_url)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGathered book list in \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mcategory\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m category: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(books_in_category_list)))\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#call the scrape_book_data which is a function that gathers all details about a single book\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m book_url \u001b[38;5;129;01min\u001b[39;00m books_in_category_list:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# create a list of data elements which will be used as column headers in the final output\n",
    "book_data = pd.DataFrame(columns=[\"product_page_url\",\"universal_product_code\",\"book_title\",\"price_including_tax\",\"price_excluding_tax\",\"quantity_available\",\"product_description\",\"category\",\"review_rating\",\"image_url\"])\n",
    "\n",
    "# define the URL to scrape data off of and define it as the url variable\n",
    "site_page_url = \"https://books.toscrape.com/\"\n",
    "\n",
    "#gather list of categories by calling function\n",
    "scraped_category_list = get_book_categories(site_page_url)\n",
    "\n",
    "#gather list of books in a category by calling function and passing the category url\n",
    "for category, category_url in scraped_category_list.items():\n",
    "    print(\"Starting category: \"+category)\n",
    "    books_in_category_list = get_books_in_category(category_url)\n",
    "    print(\"Gathered book list in \"+category+\" category: \"+str(len(books_in_category_list)))\n",
    "\n",
    "    #call the scrape_book_data which is a function that gathers all details about a single book\n",
    "    for book_url in books_in_category_list:\n",
    "        scraped_book_data = scrape_book_data(book_url)\n",
    "\n",
    "        #check to see if the extracted book is already in the list of scraped book data, if it is not, add it to the list\n",
    "        if not book_data[\"universal_product_code\"].isin([scraped_book_data[1]]).any():\n",
    "            book_data.loc[len(book_data)] = scraped_book_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e23543-46ec-4e4f-9c60-3a598806d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the book_data dataframe to CSV\n",
    "book_data.to_csv(\"Phase_1_Output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14495dd8-b333-4107-a7d6-db8a6d2b2c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
