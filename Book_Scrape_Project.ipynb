{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52069286-13fe-4542-ab00-e0d7bb8a7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# Import the requests package\n",
    "import requests\n",
    "\n",
    "# Import the beautifulsoup package\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8de70d2-0f1b-4f8c-aacb-7d97846a8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function that creates a list of book categories by passing the url and returning a list of categories\n",
    "def get_book_categories(site_url):\n",
    "    page = requests.get(site_url)\n",
    "\n",
    "    # create soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    #look for the side_categories container\n",
    "    category_container = soup.find(\"div\", class_=\"side_categories\")\n",
    "    #print(category_container)\n",
    "\n",
    "    #create a list to store all the extracted categories\n",
    "    category_list = {}\n",
    "    for category in category_container.find_all(\"a\", href=True):\n",
    "        key = category.text.strip()\n",
    "        value = \"https://books.toscrape.com\"+category[\"href\"]\n",
    "        category_list[key] = value\n",
    "\n",
    "    #remove first item in the list since it is a header\n",
    "    category_list.pop(list(category_list.keys())[0])\n",
    "    #print(category_list)\n",
    "    \n",
    "    return category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e948654-ffb0-4542-ab3c-321ce7dae628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the books on a page\n",
    "def get_books_in_category(site_url):\n",
    "    books_in_category_url = []\n",
    "    books_in_category_url.clear()\n",
    "\n",
    "    base_url = \"https://books.toscrape.com/catalogue/category/books/mystery_3/\"\n",
    "    current_page_index = \"index.html\"\n",
    "\n",
    "    #check to see if the page has pagination, if it does will loop the pages\n",
    "    while True:\n",
    "        current_page_url = base_url+current_page_index\n",
    "        page = requests.get(current_page_url) #has pagination\n",
    "        #page = requests.get(\"https://books.toscrape.com/catalogue/category/books/politics_48/index.html\") #does not have pagination\n",
    "\n",
    "        # create soup object\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        #look for books in the table on the page\n",
    "        books_container = soup.find_all(\"h3\")\n",
    "\n",
    "        #get the URL of the books on the current page\n",
    "        for image_container in books_container:\n",
    "            book_href = image_container.find(\"a\", href=True)\n",
    "            books_in_category_url.append(\"https://books.toscrape.com/catalogue/\"+book_href[\"href\"].replace(\"../../../\",\"\"))    \n",
    "\n",
    "        #check to see if there is another page\n",
    "        next_page = (soup.find(\"li\", class_=\"next\"))\n",
    "\n",
    "        #if there is a next page, get the url of the page\n",
    "        if next_page:\n",
    "            current_page_index = next_page.find(\"a\")[\"href\"]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    #print(books_in_category_url)\n",
    "\n",
    "    return books_in_category_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2acfc08-320d-4f83-9d82-b1ad0101dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function which scrapes data for a single book, pass URL return elements\n",
    "def scrape_book_data(book_page_url):\n",
    "    # set the page variable to the extract of the url's HTML\n",
    "    page = requests.get(book_page_url)\n",
    "    \n",
    "    # create soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Get the Product Description\n",
    "    #find the description container by ID\n",
    "    description_container = soup.find(\"div\", id=\"product_description\")\n",
    "    #find the next P tag after the descrption container\n",
    "    product_description =  description_container.find_next(\"p\").text.strip()\n",
    "    #print(product_description)\n",
    "\n",
    "    # Get book category\n",
    "    breadcrumb_container = soup.find(\"ul\", class_=\"breadcrumb\")\n",
    "    #print(breadcrumb_container)\n",
    "\n",
    "    #extract all the A from the container\n",
    "    list_item = breadcrumb_container.find_all(\"a\")\n",
    "    #print(list_item)\n",
    "\n",
    "    #get the category as the 3rd entry in the list\n",
    "    category = list_item[2].text.strip()\n",
    "    #print(category)\n",
    "\n",
    "    # Get the book Title as the 4th entry in the list\n",
    "    book_title = breadcrumb_container.find(\"li\",class_=\"active\").text\n",
    "    #print(book_title)\n",
    "\n",
    "    # Get the rating from the product_main div by extracting the class for star-rating\n",
    "    rating_container = soup.find(\"div\",class_=\"col-sm-6 product_main\")\n",
    "    review_rating = rating_container.find(\"p\", class_=\"star-rating\").get(\"class\")[1]\n",
    "    #print(review_rating)\n",
    "\n",
    "    # Get the Product Information table data\n",
    "    product_information_container = soup.find(\"table\", class_=\"table table-striped\")\n",
    "\n",
    "    # since we need to extract multiple data points from the table, create a dictionary to store all the data points in the product information table\n",
    "    product_information = {}\n",
    "\n",
    "    # loop the rows in the container looking for the table row (TR) tag\n",
    "    for table_row in product_information_container.find_all(\"tr\"):\n",
    "        # define the key as the extracted table header (TH)\n",
    "        key = table_row.find(\"th\").text.strip()\n",
    "        # define the value as the extracted table description (TD)\n",
    "        value = table_row.find(\"td\").text.strip()\n",
    "\n",
    "        #write the key:value pair to the dictionary\n",
    "        product_information[key] = value\n",
    "\n",
    "    #print(product_information)\n",
    "\n",
    "    #define the variables of the required information\n",
    "    universal_product_code = product_information[\"UPC\"]\n",
    "    price_including_tax = product_information[\"Price (incl. tax)\"]\n",
    "    price_excluding_tax = product_information[\"Price (excl. tax)\"]\n",
    "    quantity_available = product_information[\"Availability\"]   #NEED TO EXTRACT JUST THE NUMBER ONLY this should be fine as is without extracting extra number. if extract number , do regex\n",
    "    #print(quantity_available)\n",
    "\n",
    "    # Get the Image URL\n",
    "    thumbnail_container = soup.find(\"div\",class_=\"thumbnail\")\n",
    "    #print(thumbnail_container)\n",
    "\n",
    "    image_url = \"https://books.toscrape.com\"+thumbnail_container.find(\"img\")[\"src\"].replace(\"../..\",\"\")\n",
    "    #print(image_url)\n",
    "\n",
    "    book_extracted_information = [book_page_url,universal_product_code,book_title,price_including_tax,price_excluding_tax,quantity_available,product_description,category,review_rating,image_url]\n",
    "\n",
    "    return book_extracted_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26a8cb90-a033-44c4-b537-149dc8ea95cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of data elements which will be used as column headers in the final output\n",
    "book_data = pd.DataFrame(columns=[\"product_page_url\",\"universal_product_code\",\"book_title\",\"price_including_tax\",\"price_excluding_tax\",\"quantity_available\",\"product_description\",\"category\",\"review_rating\",\"image_url\"])\n",
    "\n",
    "# define the URL to scrape data off of and define it as the url variable\n",
    "site_page_url = \"https://books.toscrape.com/\"\n",
    "\n",
    "#gather list of categories by calling function\n",
    "#scraped_category_list = get_book_categories(site_page_url)\n",
    "\n",
    "#gather list of books in a category by calling function and passing the category url\n",
    "books_in_category_list = get_books_in_category(\"https://books.toscrape.com/catalogue/category/books/mystery_3/index.html\")\n",
    "\n",
    "#call the scrape_book_data which is a function that gathers all details about a single book\n",
    "for book_url in books_in_category_list:\n",
    "    scraped_book_data = scrape_book_data(book_url)\n",
    "\n",
    "    #check to see if the extracted book is already in the list of scraped book data, if it is not, add it to the list\n",
    "    if not book_data[\"universal_product_code\"].isin([scraped_book_data[1]]).any():\n",
    "        #print(book_data)\n",
    "        #print(book_data.shape)\n",
    "        book_data.loc[len(book_data)] = scraped_book_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0e23543-46ec-4e4f-9c60-3a598806d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the book_data dataframe to CSV\n",
    "book_data.to_csv(\"Phase_1_Output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e6e08-cf91-4805-8bfe-d979dfcc1fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 2/24 meeting\n",
    "\"\"\"\n",
    "1. fix title - DONE\n",
    "2. get rating - DONE\n",
    "3.working csv - DONE\n",
    "4. turn into function - DONE\n",
    "5. try on mystery category (has multiple pages), consider categories witout multiple pages\n",
    "6. take git hub course\n",
    "7. test pushing code to github\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
