{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52069286-13fe-4542-ab00-e0d7bb8a7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for a dataframe which will be used to store the book information prior to writing to a csv\n",
    "import pandas as pd\n",
    "\n",
    "# Import the requests package for sending HTTP requests\n",
    "import requests\n",
    "\n",
    "# Import the beautifulsoup package for parsing the website's HTML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Import re for RegEx build which is used to extract the availability of a book\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2acfc08-320d-4f83-9d82-b1ad0101dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function scrapes data for a single book by passing the book's URL and the book's elements are returned\n",
    "def scrape_book_data(book_page_url):\n",
    "    # Get the book's page HTML\n",
    "    page = requests.get(book_page_url)\n",
    "    \n",
    "    # Create soup object for parsing\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Get the Product Description by finding the product description container\n",
    "    description_container = soup.find(\"div\", id=\"product_description\")\n",
    "    \n",
    "    # As some books do not contain a description on the page, check to see if the container exists\n",
    "    # If the container does exist get the description text\n",
    "    if description_container:\n",
    "        # Find the next 'p' tag after the descrption container\n",
    "        product_description =  description_container.find_next(\"p\").text.strip()\n",
    "    else:\n",
    "        # Return nothing if the description container is not found on the page\n",
    "        product_description = \"\"\n",
    "\n",
    "    # Get book category by finding the breadcrumb\n",
    "    breadcrumb_container = soup.find(\"ul\", class_=\"breadcrumb\")\n",
    "\n",
    "    # Extract all of the 'a' tags from the breadcrumb\n",
    "    list_item = breadcrumb_container.find_all(\"a\")\n",
    "\n",
    "    # Get the category as the 3rd entry in the list\n",
    "    category = list_item[2].text.strip()\n",
    "\n",
    "    # Get the book title from the list item's in the breadcrumb\n",
    "    book_title = breadcrumb_container.find(\"li\",class_=\"active\").text\n",
    "\n",
    "    # Find the container that holds the book's rating\n",
    "    rating_container = soup.find(\"div\",class_=\"col-sm-6 product_main\")\n",
    "\n",
    "    # Get the rating from the rating container by extracting the class for star-rating\n",
    "    # The class extracts a list where the first item is the class and the second item is the actual rating\n",
    "    review_rating = rating_container.find(\"p\", class_=\"star-rating\").get(\"class\")[1]\n",
    "\n",
    "    # Get the Product Information table data which contains multiple elements for the book\n",
    "    product_information_container = soup.find(\"table\", class_=\"table table-striped\")\n",
    "\n",
    "    # Since multiple data points need to be extracted from the table, create a dictionary to store all the data points in\n",
    "    product_information = {}\n",
    "\n",
    "    # loop the table rows in the product information container\n",
    "    for table_row in product_information_container.find_all(\"tr\"):\n",
    "        # Define the key as the extracted table header (TH) which is the name of the element\n",
    "        key = table_row.find(\"th\").text.strip()\n",
    "        \n",
    "        # Define the value as the extracted table description (TD) whichs is the value of the element\n",
    "        value = table_row.find(\"td\").text.strip()\n",
    "\n",
    "        # Write the key:value pair to the dictionary\n",
    "        product_information[key] = value\n",
    "\n",
    "    # Define the variables and gather the required information\n",
    "    universal_product_code = product_information[\"UPC\"]\n",
    "    price_including_tax = product_information[\"Price (incl. tax)\"]\n",
    "    price_excluding_tax = product_information[\"Price (excl. tax)\"]\n",
    "\n",
    "    # Get the quantity available. The extracted value comes out as 'In stock (XX availabile)\". Extract the actual number via RegEx\n",
    "    quantity_available = re.findall(r\"\\d+\",product_information[\"Availability\"])[0]\n",
    "    \n",
    "    # Get the Image URL by finding the thumbnail container\n",
    "    thumbnail_container = soup.find(\"div\",class_=\"thumbnail\")\n",
    "\n",
    "    # Create the URL for the image. Since the image URL is relative, make it absolute\n",
    "    image_url = thumbnail_container.find(\"img\")[\"src\"].replace(\"../..\",\"https://books.toscrape.com\")\n",
    "\n",
    "    # Write the extracted values to the book_extracted_information list to be returned\n",
    "    book_extracted_information = [book_page_url,universal_product_code,book_title,price_including_tax,price_excluding_tax,quantity_available,product_description,category,review_rating,image_url]\n",
    "    \n",
    "    return book_extracted_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a8cb90-a033-44c4-b537-149dc8ea95cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# Create pandas dataframe and set the column headers to the data elements being extracted\n",
    "book_data = pd.DataFrame(columns=[\"product_page_url\",\"universal_product_code\",\"book_title\",\"price_including_tax\",\"price_excluding_tax\",\"quantity_available\",\"product_description\",\"category\",\"review_rating\",\"image_url\"])\n",
    "\n",
    "# Book URL\n",
    "book_url = \"https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\"\n",
    "\n",
    "# Call function to extract book data\n",
    "scraped_book_data = scrape_book_data(book_url)\n",
    "\n",
    "# Check to see if the extracted book is already in the list of scraped book data, if it is not, add it to the dataframe\n",
    "if not book_data[\"universal_product_code\"].isin([scraped_book_data[1]]).any():\n",
    "    book_data.loc[len(book_data)] = scraped_book_data\n",
    "\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0e23543-46ec-4e4f-9c60-3a598806d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the book_data dataframe to CSV\n",
    "book_data.to_csv(\"Phase_I_Extracted_Book_Data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
